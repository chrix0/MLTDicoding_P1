# -*- coding: utf-8 -*-
"""Proyek 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Qn1KvBheESLpss1CBgfXVKtV1lSU0xtV

# **Data Diri**
* Nama Lengkap: Chris Tianto Pratama
* Username: chrix0n
* Email: christiantopratama@gmail.com



---

# **Import**
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import zipfile
import pandas as pd
import tensorflow as tf
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from google.colab import files
from lightgbm import LGBMRegressor
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error
from scipy import stats

"""# **Data Loading**

Link dataset: https://www.kaggle.com/datasets/mirichoi0218/insurance?datasetId=13720
"""

! pip install -q kaggle
files.upload() #Upload kaggle.json

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

# Download dataset
! kaggle datasets download -d mirichoi0218/insurance

local_zip = '/content/insurance.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content')
zip_ref.close()

df = pd.read_csv('insurance.csv')

df

"""# **Exploratory Data Analysis (EDA)**

# Deskripsi Variabel

| Nama fitur | Deskripsi | Tipe data |
|---|---|---|
|age| Umur pemegang polis asuransi kesehatan. |int64|
|sex| Jenis kelamin pemegang polis asuransi kesehatan. |object|
|bmi| Indeks massa tubuh pemegang polis asuransi kesehatan. |float64|
|children| Jumlah anak yang ditanggung oleh asuransi kesehatan. |int64|
|smoker| Menunjukkan apakah pemegang polis asuransi kesehatan merupakan perokok. |object|
|region| Daerah perumahan pemegang polis asuransi kesehatan di Amerika Serikat (northeast, southeast, southwest, northwest). |object|
|charges| Iuran atau premi asuransi kesehatan yang harus dibayar oleh pemegang polis asuransi. |float64 |
"""

# Informasi dataset
df.info()

df.describe()

"""Pemeriksaan missing value"""

age = (df.age < 0).sum()
bmi = (df.bmi <= 0).sum()
children = (df.children < 0).sum()
charges = (df.charges <= 0).sum()

print("Jumlah data dengan nilai di bawah 0 pada kolom age: ", age)
print("Jumlah data dengan nilai 0 atau di bawahnya pada kolom bmi: ", bmi)
print("Jumlah data dengan nilai di bawah 0 pada kolom children: ", children)
print("Jumlah data dengan nilai 0 atau di bawahnya pada kolom charges: ", charges)

"""Tidak ada missing value, sehingga tidak ada data yang dihapus.

# Outlier Data

Visualisasi data dengan box plot untuk mendeteksi data outlier.
"""

sns.boxplot(x=df['age'])

sns.boxplot(x=df['bmi'])

sns.boxplot(x=df['children'])

sns.boxplot(x=df['charges'])

"""Terdapat data outlier pada fitur bmi dan charges, sehingga perlu dihapus untuk meningkatkan performa model. Pengidentifikasian data outlier dapat dilakukan dengan metode IQR."""

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1
df = df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]

df.shape

"""Jumlah data berkurang menjadi 1193

# Univariate Analysis
"""

numerical_features = ['age', 'children', 'bmi', 'charges']
categorical_features = ['sex', 'smoker', 'region']

sns.set()

"""**Analisis fitur kategori**

**Fitur sex**
"""

feature = categorical_features[0]

counter = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
temp = pd.DataFrame({'Jumlah data':counter, 'Persentase':percent.round(1)})
print(temp)

counter.plot(kind='bar', title="Fitur " + feature);

plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""Fitur sex terdiri atas dua kategori, yaitu male dan female. Grafik di atas menunjukkan bahwa jumlah data dengan jenis kelamin perempuan lebih banyak daripada laki-laki.

**Fitur smoker**
"""

feature = categorical_features[1]

counter = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
temp = pd.DataFrame({'Jumlah data':counter, 'Persentase':percent.round(1)})
print(temp)

counter.plot(kind='bar', title="Fitur " + feature);
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""Fitur smoker terdiri atas dua kategori, yaitu yes dan no. Dalam dataset ini, jumlah data untuk pemegang polis asuransi yang tidak merokok jauh lebih banyak daripada yang merokok.

**Fitur region**
"""

feature = categorical_features[2]

counter = df[feature].value_counts()
percent = 100 * df[feature].value_counts(normalize=True)
temp = pd.DataFrame({'Jumlah data':counter, 'Persentase':percent.round(1)})
print(temp)

counter.plot(kind='bar', title="Fitur " + feature);
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

"""Fitur region terdiri atas empat kategori, yaitu northwest, southeast, northeast, dan southwest. Keempat kategori teresbut memiliki jumlah data dengan persentase kurang lebih 25%. Di antara semua kategori pada fitur region, region northwest memiliki jumlah data tertinggi, sedangkan region southwest memiliki jumlah data terendah.

**Analisis fitur numerik**
"""

df.hist(bins=15, column=numerical_features, figsize=(10,10))
plt.show()

"""- Distribusi nilai fitur charges bersifat miring ke kanan (right-skewed).
- Sebagian besar pemegang polis asuransi memiliki premi dari rentang 0 sampai 15000.
- Sebagian besar pemegang polis asuransi memiliki bmi sekitar 30.
- Jumlah data pemegang polis asuransi yang berumur 20 tahun merupakan yang terbanyak.
- Sebagian besar pemegang polis asuransi belum meiliki anak.

# Multivariate Analysis

https://www.kaggle.com/code/antoniosabatini/anemia-eda-max-accuracy-features-selection
"""

for col in categorical_features:
  sns.catplot(x=col, y="charges", kind="bar", dodge=False, height = 4, aspect = 3,  data=df, palette="deep")
  plt.title("Rata-rata Charges Relatif Terhadap Variabel {}".format(col))

"""Grafik di atas menunjukkan bahwa:
- Jenis kelamin pemilik asuransi kesehatan tidak memiliki dampak yang besar terhadap biaya asuransi. Pada grafik biaya yang ditanggung oleh pemilik dengan jenis kelamin perempuan sedikit lebih besar daripada pemilik dengan jenis kelamin laki-laki.
- Pemilik asuransi yang merokok memiliki tagihan biaya asuransi yang lebih besar daripada pemilik asurasi yang tidak merokok.
- Pemilik asuransi yang berasal dari US bagian northeast memiliki biaya asuransi tertinggi, sedangkan bagian southwest memiliki biaya asuransi terendah.
"""

sns.pairplot(df, diag_kind= 'kde', height=3)

"""Pairplot di atas menunjukkan bahwa:
- Biaya asuransi meningkat seiring dengan umur pemegang polis asuransi.
- Tidak terlihat hubungan atau kolerasi antara fitur *children* dan bmi dengan fitur *charges*.

**Mengukur skor kolerasi**
"""

correlation_matrix = df.corr().round(2)
plt.figure(figsize=(10, 8))
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""Pada correlation matrix di atas terlihat bahwa terdapat kolerasi yang jelas antara fitur age dan fitur charges. 

Fitur bmi dan children memiliki kolerasi yang sangat rendah terhadap fitur charges (mendekati 0), sehingga kedua fitur tersebut dapat dihapus.
"""

df.drop(['bmi', 'children'], inplace=True, axis=1)
df.head()

"""# Data Preparation

Encoding fitur kategori dengan One-Hot Encoding
"""

df = pd.concat([df, pd.get_dummies(df['sex'], prefix='Sex')],axis=1)
df = pd.concat([df, pd.get_dummies(df['smoker'], prefix='Smoker')],axis=1)
df = pd.concat([df, pd.get_dummies(df['region'], prefix='Region')],axis=1)

df.drop(['sex','smoker','region'], axis=1, inplace=True)

df

"""Fitur sex, smoker, dan region telah diubah menjadi kumpulan fitur dummy numerik.

# Train Test Split

Dataset dipisah menjadi 80% data training dan 20% data testing.
"""

from sklearn.model_selection import train_test_split
 
y = df["charges"]
x = df.drop(["charges"], axis=1)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=66) #80% Train 20% Test

print([len(x_train), len(y_train)])
print([len(x_test), len(y_test)])

x_train

y_train

"""# Standarisasi

Pada tahap ini dilakukan standarisasi terhadap fitur age data training dan data testing. Standarisasi dilakukan dengan metode StandardScaler dengan library ScikitLearn.

Data training
"""

scaler = StandardScaler()

s_train = x_train["age"].to_numpy().reshape(-1, 1)
scaler.fit(s_train)

x_train[["age"]]= scaler.transform(x_train[["age"]])
x_train["age"].head()

"""Data testing"""

s_test = x_test["age"].to_numpy().reshape(-1, 1)
scaler.fit(s_test)

x_test[["age"]]= scaler.transform(x_test[["age"]])
x_test["age"].head()

x_train[["age"]].describe().round(4)

x_test[["age"]].describe().round(4)

"""# Model Development

Menentukan hyperparameter terbaik untuk setiap algoritma dengan Grid Search
"""

#List algo yang digunakan dengan parameter-parameter yang akan diuji
algo = {
        'KNN': {
            'model': KNeighborsRegressor(),
            'param': {
                'n_neighbors': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
                'weights': ['uniform', 'distance'],
                'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']
            }
        },
        'RandomForest': {
            'model': RandomForestRegressor(),
            'param': {
                'n_estimators': [5, 10, 25, 50, 75, 100],
                'max_depth' : [4, 8, 16, 32, 64, None],
                'random_state': [11, 22, 33, 44, 55],
                'min_samples_leaf': [1, 2, 4, 8, 16]
            }
        },
        'AdaBoost': {
            'model': AdaBoostRegressor(),
            'param': {
                'learning_rate' : [0.1, 0.05, 0.01, 0.005, 0.0015, 0.001],
                'n_estimators': [5, 10, 25, 50, 75, 100],
                'random_state': [11, 22, 33, 44, 55],
                'loss': ['linear', 'square', 'exponential']
            }
        },
        'GradientBoosting': {
            'model': GradientBoostingRegressor(),
            'param': {
                'learning_rate' : [0.1, 0.05, 0.01, 0.05, 0.0015, 0.001],
                'n_estimators': [5, 10, 25, 50, 75, 100],
                'max_depth': [3, 6, 12, 24, 48],
                'random_state': [11, 22, 33, 44, 55]
            }
        },
        'LGBM': {
            'model': LGBMRegressor(),
            'param': {
                'boosting_type' : ['gbdt', 'dart', 'goss', 'rf'],
                'learning_rate' : [0.1, 0.05, 0.01, 0.005, 0.0015, 0.001],
                'n_estimators': [5, 10, 25, 50, 75, 100],
                'random_state': [11, 22, 33, 44, 55],
            }
        }
    }

res = []

for nama, prop in algo.items():
  grid =  GridSearchCV(prop['model'], prop['param'], cv=10, n_jobs = -1, return_train_score=False, verbose=2)
  grid.fit(x,y)
  res.append({
      'model': nama,
      'best_score': grid.best_score_,
      'best_params': grid.best_params_
  })

pd.DataFrame(res,columns=['model','best_score','best_params'])

"""Parameter terbaik setiap algoritma digunakan dalam pelatihan model.

**K-Nearest Neighbor**
"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor(n_neighbors=9, algorithm='brute', weights='uniform')
knn.fit(x_train, y_train)

"""**Random Forest**"""

RF = RandomForestRegressor(n_estimators=25, max_depth=4, random_state=33, min_samples_leaf=16, n_jobs=-1)
RF.fit(x_train, y_train)

"""**AdaBoost**"""

adaboost = AdaBoostRegressor(learning_rate=0.01, n_estimators=5, loss='exponential', random_state=22)                             
adaboost.fit(x_train, y_train)

"""**GradientBoosting**"""

gb = GradientBoostingRegressor(learning_rate=0.05, max_depth=3, max_features='sqrt',
                               n_estimators=75, random_state=11, criterion='squared_error')
gb.fit(x_train, y_train)

"""**LGBM Regressor**"""

lgbm = LGBMRegressor(boosting_type='goss', learning_rate=0.05, n_estimators=50, random_state=44)
lgbm.fit(x_train, y_train)

"""# Evaluasi Model

Evaluasi dilakukan dengan dua metrik, yaitu *Mean Squared Error* (MSE) dan *Mean Absolute Error* (MAE)
"""

mse = pd.DataFrame(columns=['MSE Train', 'MSE Test'])
mae = pd.DataFrame(columns=['MAE Train', 'MAE Test'])
model_dict = {'KNN': knn, 'RandomForest': RF, 'AdaBoost': adaboost, 'GradientBoosting':gb, 'LGBM':lgbm}
 
for name, model in model_dict.items():
    mse.loc[name, 'MSE Train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(x_train))/1e3 
    mse.loc[name, 'MSE Test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(x_test))/1e3
    mae.loc[name, 'MAE Train'] = mean_absolute_error(y_true=y_train, y_pred=model.predict(x_train))
    mae.loc[name, 'MAE Test'] = mean_absolute_error(y_true=y_test, y_pred=model.predict(x_test))

mse

mae

fig, ax = plt.subplots(figsize=(12,10))
mse.sort_values(by='MSE Test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
plt.legend(loc='upper right')
ax.grid(zorder=0)

fig, ax = plt.subplots(figsize=(12,10))
mae.sort_values(by='MAE Test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
plt.legend(loc='upper right')
ax.grid(zorder=0)

"""Algoritma Random Forest memiliki nilai MSE dan MAE terendah dalam prediksi data testing.

**Uji prediksi**
"""

data = x_test.iloc[:1].copy()
pred_dict = {'y_true (nilai aktual)':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(data).round(1)
 
pd.DataFrame(pred_dict)

"""Algoritma Random Forest memberikan prediksi yang mendekati nilai aktual."""